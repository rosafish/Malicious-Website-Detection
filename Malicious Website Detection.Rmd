---
title: "Final Project Code Appendix"
author: "Weijia Ma and Rosa Zhu"
date: "5/17/2018"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
set.seed(1)
par(ask=F)
library(ggformula)
library(gridExtra)
library(broom)
library(dplyr)
library(tidyr)
library(stringr)
library(car)
library(GGally)
library(pander)
library(purrr)
library(MASS)
library(effects)
library(ROCR)
```

# Load Dataset

```{r}
website <- read.csv("~/Desktop/Malicious-Website-Detection/benign_or_malicious_website.csv")
```


# Data Wrangling and Cleaning

We find that the dataset is not cleaned for analysis yet, so we did data wrangling and cleaning first. We turned all character data to uppercase, removed the less useful variable and id varaible. We also combined some levels of the categorical variables server and country because they have too many (>20) levels to conduct intepretation. We kept "NONE" as a level to indicate unavailable information because it might mean that the information could not be fetched by the researcher due to the covert nature of the website.

We also transformed the registration date from server response to be the number of days it is away from the first registration date in the dataset, and we added a indicator variable for whether the registration date is unknown (1 for unknown, and 0 for known). We performed the same transformation on the updated date from server response.

```{r}
# upper case
website <- website %>% mutate_if(is.factor, toupper)
website <- website %>% mutate_if(is.character, as.factor)
# omitting NA values in the dataset
website <- na.omit(website)
# getting rid of WHOIS_STATEPRO and URL
website <- website %>% 
  dplyr::select(-c(WHOIS_STATEPRO, URL))
# simplify SERVER
website <- website %>% 
  mutate(SERVER = str_replace_all(SERVER, pattern = "APACHE.*", "APACHE")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "MICROSOFT.*", "MICROSOFT")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "ATS.*", "ATS")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "NGINX.*", "NGINX")) %>%
  mutate(SERVER = factor(SERVER))
# main SERVER
main.server <- c("APACHE", "GSE", "MICROSOFT", "NGINX", "NONE")
# wrong SERVER
wrong.server <- c("XXXXXXXXXXXXXXXXXXXXXX", "YIPPEE-KI-YAY", "WWW.LEXISNEXIS.COM  9999", "SERVER")
# combine wrong and main SERVER
server.comb <- combine(main.server, wrong.server)
# simplify SERVER, all values not in main server or wrong server lists are set to be "OTHER", 
# values in wrong server lists are set to be "SUSPICIOUS"
website <- website %>% 
  mutate(SERVER = as.factor(ifelse(SERVER %in% server.comb, as.character(SERVER), "OTHER"))) %>%
  mutate(SERVER = as.factor(ifelse(SERVER %in% wrong.server, "SUSPICIOUS", as.character(SERVER))))
# simplify WHOIS_COUNTRY
website <- website %>% 
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, ".*UK.*", "UK")) %>%
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, "UNITED KINGDOM", "UK")) %>%
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, "GB", "UK")) %>%
  mutate(WHOIS_COUNTRY = factor(WHOIS_COUNTRY))
main.country <- c("UK", "US", "CA", "NONE")
website <- website %>% 
  mutate(WHOIS_COUNTRY = as.factor(ifelse(WHOIS_COUNTRY %in% main.country, as.character(WHOIS_COUNTRY), "OTHER"))) %>%
  mutate(WHOIS_COUNTRY = relevel(WHOIS_COUNTRY, ref = "NONE"))
# simplify CHARSET
website <- website %>% 
  mutate(CHARSET = str_replace_all(CHARSET, pattern = "ISO-8859.*", "ISO-8859")) %>%
  mutate(CHARSET = str_replace_all(CHARSET, pattern = "WINDOWS.*", "WINDOWS")) %>%
  mutate(CHARSET = as.factor(CHARSET))
# simplify WHOIS_REGDATE
website <- website %>%
  mutate(WHOIS_REGDATE = as.Date(WHOIS_REGDATE, format = ifelse(grepl("T", as.Date(WHOIS_REGDATE)), "%Y-%m-%dT", "%d/%m/%Y"))) %>% 
  mutate(WHOIS_REGDATE = as.numeric(difftime(WHOIS_REGDATE, as.Date("1990-07-26"), units = "days"))) %>%
  mutate(NA_REGDATE = as.factor(ifelse(is.na(WHOIS_REGDATE), 1, 0))) 
mean.reg.date <- mean(website$WHOIS_REGDATE, na.rm = TRUE)
website <- website %>%
  mutate(WHOIS_REGDATE = ifelse(is.na(WHOIS_REGDATE), mean.reg.date, WHOIS_REGDATE))
# simplify WHOIS_UPDATED_DATE
website <- website %>%
  mutate(WHOIS_UPDATED_DATE = as.Date(WHOIS_UPDATED_DATE, format = ifelse(grepl("T", WHOIS_UPDATED_DATE), "%Y-%m-%dT", "%d/%m/%Y"))) %>%
  mutate(WHOIS_UPDATED_DATE = as.numeric(difftime(WHOIS_UPDATED_DATE, as.Date("2008-07-14"), units = "days"))) %>%
  mutate(NA_UPDATED_DATE = as.factor(ifelse(is.na(WHOIS_UPDATED_DATE), 1, 0)))
mean.update.date <- mean(na.omit(website$WHOIS_UPDATED_DATE))
website <- website %>%
  mutate(WHOIS_UPDATED_DATE = ifelse(is.na(WHOIS_UPDATED_DATE), mean.update.date, WHOIS_UPDATED_DATE))
# factor Type
website <- website %>% mutate(Type = as.factor(Type))
website.sm <- website %>%
  mutate(WHOIS_REGDATE = ifelse(is.na(WHOIS_REGDATE), mean.reg.date, WHOIS_REGDATE))
```
  
# EDA

A numerical overview of all the varibles.

```{r}
# numerical summary of the data
web.sum <- summary(website)
pander(web.sum)
```

An graphical overview of the quantitative predictors.

```{r}
# Quantatative
# select quantitative vars
website.quant <- website %>% 
  dplyr::select(-c(SERVER, WHOIS_COUNTRY, CHARSET))
website.quant %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```

We found there to be collinearity among the predictors related of number packets and bytes generated during communication of the honeypot and the server. 

```{r}
# App Packets & Bytes
ggpairs(website[, 12:17])
```

We also explored how some of the predictor variables related to the response varible. The server brand and country both seem to have potential impact on the type of the website. Shorter url length and higher DNS query times seem to be associated with higher odds of malicious website.

```{r fig.width=5, fig.height=4}
# Charset
website %>% gf_bar(~CHARSET, fill=~Type)
table(website$CHARSET, website$Type) %>% prop.table(margin=1)

# SERVER
website %>% gf_bar(~SERVER, fill=~Type)
table(website$SERVER, website$Type) %>% prop.table(margin=1)

# REGDATE
gf_boxplot(WHOIS_REGDATE ~ Type, data = website)

# graphical summary of the data (some variables)
spineplot(Type ~ SERVER, data = website)
spineplot(Type ~ WHOIS_COUNTRY, data = website)
gf_boxplot(URL_LENGTH ~ Type, data = website)
gf_boxplot(DNS_QUERY_TIMES ~ Type, data = website)
```

# Fit Model for Inference
## Fit Full Model
```{r}
inf.mod.full <- glm(Type ~ . , data = website, family = binomial)
str(website)
summary(inf.mod.full)
# Outlier Detection and elimination
influenceIndexPlot(inf.mod.full, vars = c("Cook", "Studentized", "hat"))
residualPlots(inf.mod.full)
website <- website [-c(443,898,468,897,671,72,558),]
inf.mod.no.outlier <- glm(Type ~ . , data = website, family = binomial)
influenceIndexPlot(inf.mod.no.outlier, vars = c("Cook", "Studentized", "hat"))
# Assumption Checking
residualPlots(inf.mod.no.outlier)
```

We fit the full model of log odds of malicious website on all the variables. Through repeated influential point detection, we found 7 outliers with high Cook's Distance and/or Standardized Redisual so they are excluded from the rest of the analysis.

Assumption checking tells us that the linearity assumption is satisfied.
The data collection is random and the independence assumption could also be assumed as there is no sign of pairing or clustering.

## Model Selection

We first eliminate the multicollinear terms found during EDA. Then, we conducted stepwise selection based on AIC. 

```{r fig.height=9, fig.width=12}
# Multicollinearity (PACKETS & BYTES)
inf.mod.bytes <- update(inf.mod.no.outlier, . ~ . - (REMOTE_APP_PACKETS + SOURCE_APP_PACKETS +  REMOTE_APP_BYTES + APP_PACKETS + APP_BYTES))
anova(inf.mod.bytes, inf.mod.no.outlier, test = "Chisq")
# Stepwise selection
inf.mod.aic <- stepAIC(inf.mod.bytes,
                       scope = list(lower ~ 1),
                       direction = "both",
                       trace = 0)
pander(tidy(inf.mod.aic))
# Drop in deviance test for server and country
inf.mod.no.country <- update(inf.mod.aic, . ~ . - WHOIS_COUNTRY)
anova(inf.mod.no.country, inf.mod.aic, test = "Chisq")
inf.mod.no.server <- update(inf.mod.aic, . ~ . - SERVER)
anova(inf.mod.no.server, inf.mod.aic, test = "Chisq")
```

Certain levels in country seem to be insignificant according to the Wald test, so we conduct drop-in-deviance test on the country variable separately. The small p-value (<0.001) tells that at least the coefficient for one of the level is not 0 for country. Similar conclusion can be made about server, whose drop-in-deviance test also has a p-value < 0.001.

# Model assessment
```{r}
# Check for linearity & outliers
influenceIndexPlot(inf.mod.aic, vars = c("Cook", "Studentized", "hat"))
crPlots(inf.mod.aic)
# Check for overdispersion
1 - pchisq(209.45, 952)
inf.mod.aic$deviance/inf.mod.aic$df.residual
# Visualize the model
plot(allEffects(inf.mod.aic, title=""), rows = 3, cols = 4, main="")
```

There doesn't seem to be any outliers or non-linearity. The randomness and independence assumptions are still satisfied. The large p-value of the goodness of fit test and the small dispersion parameter (0.22) indicates that the model is adequate and that overdispersion is not likely to be present.

## Interpretation

Estimate interpretation and profile likelihood confidence interval:

```{r}
exp(coef(inf.mod.aic))
exp(confint(inf.mod.aic, level = 0.95))
```


# Fit Model for Prediction

We are optimizing accuracy of the predictive model. 

## Create Training and Test Datasets

We splited the dataset into a test set(20%) and a training set (80%) randomly. We are going to fit our model with the test set and use the training set to assess the model.

```{r}
index <- sample(1:nrow(website), size=0.2*nrow(website))
website.train <- website[-index, ]
website.test <- website[index, ]
```

## Fit Model

### Model selection based on predictive accuracy

Fit the full model and got an accuracy value of 94.3%.

```{r}
# Full model
pred.mod.full <- glm(Type ~ . , data = website.train, family = binomial)
summary(pred.mod.full)
# With full model
pred.full.col <- predict(pred.mod.full, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.full = as.factor(ifelse(as.numeric(pred.full.col) <= 0.5, 0, 1)))
(accuracy.full <- mean(website.test$pred.full == website.test$Type))
```

We then tried to eliminate the multi-collinear variables related to packets and bytes, because the redundant information provided by the correlated predictors are likely to overweigh the importance of those predictors. The newly fitted model results in an accuracy of 93.8%. To avoid overfitting, we tried to stepwise eliminate predictors based on the model with no packets or bytes predictors. We discovered that accuracy increases to 95.8% once we get rid of the server predictor. Thus the variable server is likely to lead to overfitting.

```{r}
# No packets
pred.mod.no.packet <- glm(Type ~ . -(REMOTE_APP_PACKETS + SOURCE_APP_PACKETS +  REMOTE_APP_BYTES + APP_PACKETS + APP_BYTES), data = website.train, family = binomial)
summary(pred.mod.no.packet)

# With no packet model
pred.no.packet.col <- predict(pred.mod.no.packet, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.packet = as.factor(ifelse(as.numeric(pred.no.packet.col) <= 0.5, 0, 1)))
(accuracy.no.packet <- mean(website.test$pred.no.packet == website.test$Type))

# No server and packets
pred.mod.no.server <- update(pred.mod.no.packet, . ~ . -SERVER, data = website.train, family = binomial)
summary(pred.mod.no.server)

# With no server and packets model
pred.no.server.col  <- predict(pred.mod.no.server , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.server = as.factor(ifelse(as.numeric(pred.no.server.col) <= 0.5, 0, 1)))
(accuracy.no.server <- mean(website.test$pred.no.server == website.test$Type))

# No country and packets
pred.mod.no.country <- update(pred.mod.no.packet, . ~ . -WHOIS_COUNTRY, data = website.train, family = binomial)
summary(pred.mod.no.country)

# With no country model and packets
pred.no.country.col  <- predict(pred.mod.no.country , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.country = as.factor(ifelse(as.numeric(pred.no.country.col) <= 0.5, 0, 1)))
(accuracy.no.country  <- mean(website.test$pred.no.country  == website.test$Type))

# No whois_updated_date and packets
pred.mod.no.update <- update(pred.mod.no.packet, . ~ . -WHOIS_UPDATED_DATE, data = website.train, family = binomial)
summary(pred.mod.no.update)

# No packets and whois_updated_date
pred.no.update.col <- predict(pred.mod.no.update , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.update = as.factor(ifelse(as.numeric(pred.no.update.col) <= 0.5, 0, 1)))
(accuracy.no.update <- mean(website.test$pred.no.update  == website.test$Type))
```

To further avoid overfitting, we tried to use the inferential model for prediction, and the corresponding accuracy is 95.3%.

```{r}
# Avoid overfitting, use the reduced model we got from AIC stepwise elimination
pred.mod.inf.mod.aic <- update(inf.mod.aic, Type ~ URL_LENGTH + NUMBER_SPECIAL_CHARACTERS + SERVER + CONTENT_LENGTH +
                                 WHOIS_COUNTRY + WHOIS_REGDATE + TCP_CONVERSATION_EXCHANGE + DIST_REMOTE_TCP_PORT +
                                 SOURCE_APP_BYTES + DNS_QUERY_TIMES + NA_UPDATED_DATE, data = website.train, family = binomial)
summary(pred.mod.inf.mod.aic)

# With inferential model
pred.inf.mod.aic.col <- predict(pred.mod.inf.mod.aic, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.inf.mod.aic = as.factor(ifelse(as.numeric(pred.inf.mod.aic.col) <= 0.5, 0, 1)))
(accuracy.inf.mod.aic <- mean(website.test$pred.inf.mod.aic == website.test$Type))
```

Since we have discovered previously that server predictor seem to have effects on overfitting, we eliminated the predictor and resulted in a higher accuracy of 96.4%. Further reducing the model, we eliminated the country predictor based on the new model, and the resulted accuracy did not change.

```{r}
# Inferential model with no server
pred.mod.no.server.inf <- update(pred.mod.inf.mod.aic, . ~ . -SERVER, data = website.train, family = binomial)
summary(pred.mod.no.server.inf)

# Inferential model with no server
pred.mod.no.server.inf.col <- predict(pred.mod.no.server.inf, newdata = website.test, type = "response")
pred.final.col <- predict(pred.mod.no.server.inf, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.mod.no.server.inf = as.factor(ifelse(as.numeric(pred.mod.no.server.inf.col) <= 0.5, 0, 1)))
(accuracy.mod.no.server.inf <- mean(website.test$pred.mod.no.server.inf == website.test$Type))

# Further reduce the model: getting rid of country
pred.mod.no.country.inf <- update(pred.mod.inf.mod.aic, . ~ . -(SERVER + WHOIS_COUNTRY), data = website.train, family = binomial)
summary(pred.mod.no.country.inf)

pred.mod.no.country.inf.col <- predict(pred.mod.no.country.inf, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.mod.no.country.inf = as.factor(ifelse(as.numeric(pred.mod.no.country.inf.col) <= 0.5, 0, 1)))
(accuracy.mod.no.country.inf <- mean(website.test$pred.mod.no.country.inf == website.test$Type))
```

## Comparison of the two models

To further compare the two models with accuracy of 96.4%, we plotted the ROC curves for both models. From the plots, we can see that the model with no server and country predictors has a greater area under the ROC curve, which indicates better accuracy. Moreover, since it has less variables, it is less likely to have overfitting issue than the other model. Since our goal is to maximize accuracy and avoid overfitting probelm, we chose the model with no server nor country predictors to be our final predictive model. On the other hand, the other model has a higher sensitivity than our model.

```{r fig.width=5, fig.height=4}
preds_obj2 <- prediction(pred.no.country.col, website.test$Type)
perf_obj2 <- performance(preds_obj2, "tpr","fpr")
perf_df2 <- data_frame(fpr=unlist(perf_obj2@x.values),tpr= unlist(perf_obj2@y.values), threshold=unlist(perf_obj2@alpha.values), model="No server and country")

preds_obj1 <- prediction(pred.no.server.col, website.test$Type)
perf_obj1 <- performance(preds_obj1, "tpr","fpr")
perf_df1 <- data_frame(fpr=unlist(perf_obj1@x.values),tpr= unlist(perf_obj1@y.values), threshold=unlist(perf_obj1@alpha.values), model="No server")

perf_df <- bind_rows(perf_df1, perf_df2)

ggplot(perf_df, aes(x=fpr, y=tpr, color=model)) +  geom_line() + 
  labs(x="false positive rate (1-specificity)", y="true positive rate (sensitivity)", title="ROC curve for logistic") + 
  geom_abline(slope=1,intercept=0, linetype=3) 

ggplot(perf_df1, aes(x=fpr, y=tpr, color=threshold)) +  geom_line() + 
  labs(x="false positive rate (1-specificity)", y="true positive rate (sensitivity)", title="ROC curve for logistic model with no server") + 
  geom_abline(slope=1,intercept=0, linetype=3) + 
  scale_color_gradient2(midpoint=0.5, mid="black", low="orange", high="pink")

ggplot(perf_df2, aes(x=fpr, y=tpr, color=threshold)) +  geom_line() + 
  labs(x="false positive rate (1-specificity)", y="true positive rate (sensitivity)", title="ROC curve for logistic model with no server and country") + 
  geom_abline(slope=1,intercept=0, linetype=3) + 
  scale_color_gradient2(midpoint=0.5, mid="black", low="orange", high="pink")

pred.final.sum <- summary(pred.mod.no.country.inf)
pander(cbind(pred.final.sum$coefficients), type = "pdf")
```

